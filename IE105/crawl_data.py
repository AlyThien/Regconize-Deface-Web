import requests
from bs4 import BeautifulSoup
import csv
import os

# ğŸ“¥ Äá»c danh sÃ¡ch URL tá»« file
with open("urls.txt", "r") as file:
    urls = [line.strip() for line in file.readlines() if line.strip()]

# ğŸ“ Táº¡o thÆ° má»¥c lÆ°u HTML
os.makedirs("html_pages", exist_ok=True)

# ğŸ“„ Ghi file CSV vá»›i chá»‰ 2 cá»™t: URL vÃ  HTML_File_Name
with open("defaced_data_clean.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["URL", "HTML_File_Name"])  # ğŸ‘‰ Chá»‰ 2 trÆ°á»ng

    for url in urls:
        try:
            response = requests.get(url, timeout=10)

            # âœ… Táº¡o tÃªn file HTML
            html_filename = url.replace("http://", "").replace("https://", "").replace("/", "_") + ".html"
            html_path = os.path.join("html_pages", html_filename)

            # âœ… LÆ°u ná»™i dung HTML vÃ o file
            with open(html_path, "w", encoding="utf-8") as html_file:
                html_file.write(response.text)

            # âœ… Ghi vÃ o CSV
            writer.writerow([url, html_filename])
            print(f"âœ” ÄÃ£ xá»­ lÃ½: {url}")

        except Exception as e:
            print(f"âŒ Lá»—i vá»›i {url}: {e}")
